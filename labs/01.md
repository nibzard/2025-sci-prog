
# **Scientific Programming – Exercise 1**

## Using Python and Modern Development Environments for Data Analysis

### **Session Overview**

This exercise introduced students to modern tools and workflows for scientific programming, emphasizing:

* Python’s core data analysis libraries
* Cloud-based and containerized development environments (Google Colab, GitHub Codespaces, Dev Containers)
* API-based workflows (Google Gemini API, Vertex AI)
* Reproducible project structures and environment setup
* Interactive and AI-assisted development tools (Marimo, UV, MCP servers)

---

## **Learning Objectives**

By the end of this session, you should be able to:

1. Understand the ecosystem of Python libraries for data science (NumPy, SciPy, Pandas, Matplotlib, Seaborn, Scikit-Learn).
2. Create and configure an API key for Google Gemini and integrate it in your environment.
3. Set up and use **GitHub Codespaces** as a cloud-based Python development workspace.
4. Build and configure a **Dev Container** for automatic environment setup.
5. Work with **Jupyter** and **Marimo** notebooks for interactive Python programming.
6. Use the **UV package manager** for reproducible Python project initialization.
7. Understand concepts of **AI agents**, **MCP servers**, and how they extend Python workflows.

---

## **1. Python Ecosystem for Scientific Programming**

We began with an overview of the core Python tools for data analysis and scientific computing. These libraries form the foundation for most workflows you’ll encounter.

| Library          | Purpose                                                                                 | Link                                             |
| ---------------- | --------------------------------------------------------------------------------------- | ------------------------------------------------ |
| **NumPy**        | Efficient numerical computation with multidimensional arrays and vectorized operations. | [numpy.org](https://numpy.org)                   |
| **SciPy**        | Algorithms for linear algebra, optimization, statistics, etc.                           | [scipy.org](https://scipy.org)                   |
| **Pandas**       | High-level data manipulation and analysis with DataFrames.                              | [pandas.pydata.org](https://pandas.pydata.org)   |
| **Matplotlib**   | Low-level 2D visualization; publication-quality figures.                                | [matplotlib.org](https://matplotlib.org)         |
| **Seaborn**      | High-level statistical visualizations built on Matplotlib.                              | [seaborn.pydata.org](https://seaborn.pydata.org) |
| **Scikit-Learn** | Machine learning algorithms for classification, regression, clustering, etc.            | [scikit-learn.org](https://scikit-learn.org)     |

---

## **2. Setting Up the Development Environment**

### **Google Colab**

* A cloud-based Jupyter environment—no local setup required.
* Supports free GPU usage and collaborative editing.
* Excellent for quick prototyping, sharing notebooks, and running short-term experiments.
* Access via: [https://colab.research.google.com](https://colab.research.google.com)

### **GitHub Codespaces**

* Cloud-based Visual Studio Code environment integrated with GitHub.
* Each project runs in an isolated container and can be configured via a **Dev Container file**.
* Benefits:

  * No local setup—works from any browser.
  * Persistent environment until manually stopped.
  * Easy to rebuild consistent setups across projects.

**Basic workflow demonstrated in class:**

1. Create or open a repository on GitHub.
2. Launch a new Codespace.
3. In the Codespace terminal, install dependencies, e.g.:

   ```bash
	npm install -g @google/gemini-cli
   ```
4. Configure environment variables:

   ```bash
   export GEMINI_API_KEY="your_key_here"
   ```

   or store them in a `.env` file.

---

## **3. Working with the Google Gemini API**

* Gemini provides access to Google’s generative AI models.
* You can authenticate using either:

  * Your **API key**, or
  * **Google authentication flow** (via login and authorization link).

**Tips:**

* Use `.env` to keep your keys private.
* Restart the environment if authentication fails.
* Rate limits may apply — if you receive `resource-exhausted` or `rate-limit-exceeded`, switch to a smaller model variant.

---

## **4. Creating and Configuring a Dev Container**

Dev Containers define all project dependencies in one configuration file (`devcontainer.json`), ensuring full reproducibility.

**Example workflow:**

1. In your Codespace, create a Dev Container configuration:

   ```bash
   Create dev container file to install Gemini CLI using NPM
   ```
2. Example snippet:

   ```json
   {
     "name": "Gemini Dev Environment",
     "image": "mcr.microsoft.com/devcontainers/javascript-node:20",
     "postCreateCommand": "npm install -g @google/gemini-cli"
   }
   ```
3. Rebuild the container via the **Rebuild Container** command.
4. Upon rebuild, your environment will automatically include Node.js, npm, and Gemini CLI.

**Troubleshooting:**

* If `command not found`, confirm Node.js and npm are installed in the image.
* You can base your container on `node:20` to avoid missing packages.

---

## **5. Interactive Development with Jupyter and Marimo**

### **Jupyter Notebooks**

* Work seamlessly inside Codespaces or Colab.
* Each cell can execute code or display documentation.
* Use `%matplotlib inline` to display plots directly in the notebook.

### **Marimo**

* A modern alternative to Jupyter, offering reactive notebooks and built-in AI support.
* Setup via **UV**, a fast Python environment manager written in Rust.

**Workflow:**

```bash
# Install UV
curl -fsSL https://astral.sh/uv/install.sh | sh

# Initialize a new project
uv init marimo-test
cd marimo-test

# Add and run Marimo
uv add marimo
uv run marimo
uv run marimo tutorial intro
```

**Features:**

* Reactive code execution and interactivity (sliders, dropdowns).
* Built-in AI chat integration with Gemini, OpenAI or any other models.
* Ability to connect to data sources or APIs (e.g., Zotero MCP server).

**Why Marimo?**

* Cleaner interface and modern UI compared to Jupyter.
* Suitable for lightweight dashboards and exploratory analysis.

---

## **6. MCP Servers and Agent Workflows**

* **MCP (Model Context Protocol)** lets you wrap APIs into higher-level AI tools.
* Example: Connecting a Zotero library via MCP to allow AI-based literature summarization and query.
* Enables creation of **agents** that can search, reason, and act using structured tools (data retrieval, analysis, etc.).
* Useful for research assistance, automating repetitive data collection, or integrating AI reasoning in scientific workflows.

---

## **7. Example Projects and Applications**

### **A. Data Analysis with Pandas**

Tasks demonstrated:

* Reading data:

  ```python
  df = pd.read_csv("Salaries.csv")
  ```
* Exploring data: `df.head()`, `df.describe()`, `df.dtypes()`
* Filtering and grouping:

  ```python
  df[df['salary'] > 120000]
  df.groupby('rank')[['salary']].mean()
  ```
* Handling missing values:

  ```python
  df.dropna()
  df.fillna(0)
  ```
* Visualization using Seaborn:

  ```python
  sns.boxplot(x="rank", y="salary", data=df)
  ```

### **B. Other Ideas Mentioned**

* Build a small **FastAPI backend** for multiplayer data exchange (as discussed).
* Automate **financial data collection** using browser agents (e.g., Stealth Browsers Steel.dev with Docker).
* Create a **sentiment analysis pipeline** using LLMs and web scraping.
* Integrate **Gemini API** into your Marimo notebooks for data summarization or natural language querying.

---

## **8. Troubleshooting & Tips**

| Issue                            | Solution                                                        |
| -------------------------------- | --------------------------------------------------------------- |
| **Authentication error**         | Re-run Google authentication flow or check `.env` file syntax.  |
| **Gemini “rate limit exceeded”** | Switch to a smaller model (`flash`) or wait before retrying.    |
| **Codespace missing Node/npm**   | Use Node-based Dev Container image.                             |
| **Container fails to rebuild**   | Check the `postCreateCommand` logs and confirm internet access. |
| **Colab out of memory**          | Restart runtime and limit dataset size.                         |

**Best practices:**

* Keep your `.env` and configuration files under version control **only locally** (never push API keys).
* Comment and document your notebooks thoroughly.
* Regularly test environment rebuilds to ensure reproducibility.

---

## **9. Reflection and Next Steps**

This first exercise was primarily exploratory — learning to **set up**, **experiment**, and **debug**.
You’ve now encountered a real-world development workflow similar to what data scientists and AI engineers use daily.

For the next sessions:

* Ensure your Codespace or Colab environment works.
* Familiarize yourself with `Pandas`, `NumPy`, and `Matplotlib` basics.
* Experiment with connecting external APIs (Gemini, OpenRouter or any other model provider).
* Begin thinking about your **project proposal**, ideally combining:

  * Data collection (e.g. existing databases, web scraping or API use),
  * Analysis and visualization,
  * And possibly an AI-assisted component.

---

### **IMPORTANT**

> “Everything we did today shows that there are no excuses — anything can be built.
> Even if something doesn’t work immediately, you can fix it iteratively.
> Curiosity, iteration, and persistence are the key skills of scientific programmers.”

